{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggr_Transaction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_trans\n",
    "\n",
    "path1 =\"C:/Users/Admin/OneDrive/Desktop/phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "Agg_state_list=os.listdir(path1)\n",
    "#Agg_state_list # you  wil get state list\n",
    "\n",
    "\n",
    "#This is to extract the data's to create a dataframe\n",
    "\n",
    "cols1={'State':[], 'Year':[],'Quater':[],'Transacion_type':[],\n",
    "       'Transacion_count':[], 'Transacion_amount':[]}\n",
    "\n",
    "for state in Agg_state_list:\n",
    "    cur_states=path1+state+\"/\"\n",
    "    Agg_yr=os.listdir(cur_states)\n",
    "    #agg_yr # you will get year  list\n",
    "    \n",
    "    for year in Agg_yr:\n",
    "        cur_year=cur_states+year+\"/\"\n",
    "        Agg_file=os.listdir(cur_year)\n",
    "        #agg_file  # you will get json files\n",
    "        \n",
    "        for file in Agg_file:\n",
    "            cur_file=cur_year+file\n",
    "            Data=open(cur_file,'r')\n",
    "            A=json.load(Data)\n",
    "            # A   # you will get 1.json file details\n",
    "            \n",
    "            # slicing to get data\n",
    "            for i in A['data']['transactionData']:\n",
    "                Name=i['name']\n",
    "                count=i['paymentInstruments'][0]['count']\n",
    "                amount=i['paymentInstruments'][0]['amount']\n",
    "                cols1['Transacion_type'].append(Name)\n",
    "                cols1['Transacion_count'].append(count)\n",
    "                cols1['Transacion_amount'].append(amount)\n",
    "                cols1['State'].append(state)\n",
    "                cols1['Year'].append(year)\n",
    "                cols1['Quater'].append(int(file.strip('.json')))\n",
    "                \n",
    "Agg_Trans=pd.DataFrame(cols1) \n",
    "              \n",
    "Agg_Trans['Year']= pd.to_datetime(Agg_Trans['Year']).dt.year                \n",
    "Agg_Trans['State']= Agg_Trans['State'].str.replace(\"-\",\" \")\n",
    "Agg_Trans['State']= Agg_Trans['State'].str.title()\n",
    "Agg_Trans['State']= Agg_Trans['State'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "Agg_Trans['State']= Agg_Trans['State'].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagarhaveli and Daman  and Diu')\n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggr_User**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggr_User\n",
    "\n",
    "path2 =\"C:/Users/Admin/OneDrive/Desktop/phonepe/pulse/data/aggregated/user/country/india/state/\"\n",
    "Agg_state_list=os.listdir(path2)\n",
    "#Agg_state_list # you  wil get state list\n",
    "\n",
    "\n",
    "#This is to extract the data's to create a dataframe\n",
    "\n",
    "cols2={'State':[], 'Year':[],'Quater':[],'Brands':[],\n",
    "    'Transacion_count':[], 'Percentage':[]}\n",
    "\n",
    "for state in Agg_state_list:\n",
    "    cur_states=path2+state+\"/\"\n",
    "    Agg_yr=os.listdir(cur_states)\n",
    "    #agg_yr # you will get year  list\n",
    "    \n",
    "    for year in Agg_yr:\n",
    "        cur_year=cur_states+year+\"/\"\n",
    "        Agg_file=os.listdir(cur_year)\n",
    "        #agg_file  # you will get json files\n",
    "        \n",
    "        for file in Agg_file:\n",
    "            cur_file=cur_year+file\n",
    "            Data=open(cur_file,'r')\n",
    "            B=json.load(Data)\n",
    "            #print(B)   # you will get 1.json file details\n",
    "            #print(B['data']['usersByDevice'])\n",
    "            \n",
    "            # slicing to get data\n",
    "            try:\n",
    "                for i in B['data']['usersByDevice']:\n",
    "                    Brand=i['brand']\n",
    "                    count=i['count']\n",
    "                    Percentage=i['percentage']\n",
    "                    cols2['Brands'].append(Brand)\n",
    "                    cols2['Transacion_count'].append(count)\n",
    "                    cols2['Percentage'].append(Percentage)\n",
    "                    cols2['State'].append(state)\n",
    "                    cols2['Year'].append(year)\n",
    "                    cols2['Quater'].append(int(file.strip('.json')))\n",
    "            except: \n",
    "                    pass \n",
    "                \n",
    "Agg_User=pd.DataFrame(cols2)\n",
    "\n",
    "Agg_User['Year']= pd.to_datetime(Agg_User['Year']).dt.year            \n",
    "Agg_User['State']= Agg_User['State'].str.replace(\"-\",\" \")\n",
    "Agg_User['State']= Agg_User['State'].str.title()\n",
    "Agg_User['State']= Agg_User['State'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "Agg_User['State']= Agg_User['State'].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagarhaveli and Daman  and Diu')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map_transaction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_transaction\n",
    "\n",
    "path3 =\"C:/Users/Admin/OneDrive/Desktop/phonepe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "map_state_list=os.listdir(path3)\n",
    "#map_state_list # you  wil get state list\n",
    "\n",
    "\n",
    "#This is to extract the data's to create a dataframe\n",
    "\n",
    "cols3={'State':[], 'Year':[],'Quater':[],'Districts':[],\n",
    "       'Transacion_count':[], 'Transacion_amount':[]}\n",
    "\n",
    "for state in map_state_list:\n",
    "    cur_states=path3+state+\"/\"\n",
    "    map_yr=os.listdir(cur_states)\n",
    "    #map_yr # you will get year  list\n",
    "    \n",
    "    for year in map_yr:\n",
    "        cur_year=cur_states+year+\"/\"\n",
    "        map_file=os.listdir(cur_year)\n",
    "        #map_file  # you will get json files\n",
    "        \n",
    "        for file in map_file:\n",
    "            cur_file=cur_year+file\n",
    "            Data=open(cur_file,'r')\n",
    "            C=json.load(Data)\n",
    "            #print(C)   # you will get 1.json file details\n",
    "            \n",
    "            # slicing to get data\n",
    "            for i in C['data']['hoverDataList']:\n",
    "                Name=i['name']\n",
    "                count=i['metric'][0]['count']\n",
    "                amount=i['metric'][0]['amount']\n",
    "                cols3['Districts'].append(Name)\n",
    "                cols3['Transacion_count'].append(count)\n",
    "                cols3['Transacion_amount'].append(amount)\n",
    "                cols3['State'].append(state)\n",
    "                cols3['Year'].append(year)\n",
    "                cols3['Quater'].append(int(file.strip('.json')))\n",
    "                \n",
    "map_Trans=pd.DataFrame(cols3) \n",
    " \n",
    "map_Trans['Year']= pd.to_datetime(map_Trans['Year']).dt.year              \n",
    "map_Trans['State']= map_Trans['State'].str.replace(\"-\",\" \")\n",
    "map_Trans['State']= map_Trans['State'].str.title()\n",
    "map_Trans['State']= map_Trans['State'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "map_Trans['State']= map_Trans['State'].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagarhaveli and Daman  and Diu')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map_user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_User\n",
    "path4 =\"C:/Users/Admin/OneDrive/Desktop/phonepe/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_state_list=os.listdir(path4)\n",
    "#map_state_list # you  wil get state list\n",
    "\n",
    "#This is to extract the data's to create a dataframe\n",
    "\n",
    "cols4={'State':[], 'Year':[],'Quater':[],'Districts':[],\n",
    "       'RegisteredUsers':[], 'AppOpens':[]}\n",
    "\n",
    "for state in map_state_list:\n",
    "    cur_states=path4+state+\"/\"\n",
    "    map_yr=os.listdir(cur_states)\n",
    "    #map_yr # you will get year  list\n",
    "    \n",
    "    for year in map_yr:\n",
    "        cur_year=cur_states+year+\"/\"\n",
    "        map_file=os.listdir(cur_year)\n",
    "        #map_file  # you will get json files\n",
    "        \n",
    "        for file in map_file:\n",
    "            cur_file=cur_year+file\n",
    "            Data=open(cur_file,'r')\n",
    "            D=json.load(Data)\n",
    "            #print(D)   # you will get 1.json file details\n",
    "            \n",
    "            # slicing to get data\n",
    "            for i in D['data']['hoverData'].items():\n",
    "                district=i[0]\n",
    "                registeredUsers=i[1]['registeredUsers']\n",
    "                appOpens=i[1]['appOpens']\n",
    "                cols4['Districts'].append(district)\n",
    "                cols4['RegisteredUsers'].append(registeredUsers)\n",
    "                cols4['AppOpens'].append(appOpens)\n",
    "                cols4['State'].append(state)\n",
    "                cols4['Year'].append(year)\n",
    "                cols4['Quater'].append(int(file.strip('.json')))\n",
    "                \n",
    "map_User=pd.DataFrame(cols4)                \n",
    "map_User['Year']= pd.to_datetime(map_User['Year']).dt.year\n",
    "map_User['State']= map_User['State'].str.replace(\"-\",\" \")\n",
    "map_User['State']= map_User['State'].str.title()\n",
    "map_User['State']= map_User['State'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "map_User['State']= map_User['State'].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagarhaveli and Daman  and Diu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top_transaction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_trans\n",
    "path5 =\"C:/Users/Admin/OneDrive/Desktop/phonepe/pulse/data/top/transaction/country/india/state/\"\n",
    "top_state_list=os.listdir(path5)\n",
    "#top_state_list # you  wil get state list\n",
    "\n",
    "\n",
    "#This is to extract the data's to create a dataframe\n",
    "\n",
    "cols5={'State':[], 'Year':[],'Quater':[],'Pincodes':[],\n",
    "       'Transacion_count':[], 'Transacion_amount':[]}\n",
    "\n",
    "for state in top_state_list:\n",
    "    cur_states=path5+state+\"/\"\n",
    "    top_yr=os.listdir(cur_states)\n",
    "    #top_yr # you will get year  list\n",
    "    \n",
    "    for year in top_yr:\n",
    "        cur_year=cur_states+year+\"/\"\n",
    "        top_file=os.listdir(cur_year)\n",
    "        #top_file  # you will get json files\n",
    "        \n",
    "        for file in top_file:\n",
    "            cur_file=cur_year+file\n",
    "            Data=open(cur_file,'r')\n",
    "            E=json.load(Data)\n",
    "            #print(E)   # you will get 1.json file details\n",
    "            \n",
    "            # slicing to get data\n",
    "            for i in E['data']['pincodes']:\n",
    "                entityName=i['entityName']\n",
    "                count=i['metric']['count']\n",
    "                amount=i['metric']['amount']\n",
    "                cols5['Pincodes'].append(entityName)\n",
    "                cols5['Transacion_count'].append(count)\n",
    "                cols5['Transacion_amount'].append(amount)\n",
    "                cols5['State'].append(state)\n",
    "                cols5['Year'].append(year)\n",
    "                cols5['Quater'].append(int(file.strip('.json')))\n",
    "                \n",
    "top_Trans=pd.DataFrame(cols5)   \n",
    "top_Trans['Year']= pd.to_datetime(top_Trans['Year']).dt.year \n",
    "top_Trans['State']= top_Trans['State'].str.replace(\"-\",\" \")\n",
    "top_Trans['State']= top_Trans['State'].str.title()\n",
    "top_Trans['State']= top_Trans['State'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "top_Trans['State']= top_Trans['State'].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagarhaveli and Daman  and Diu')            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**top_User**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_User\n",
    "path6 =\"C:/Users/Admin/OneDrive/Desktop/phonepe/pulse/data/top/user/country/india/state/\"\n",
    "top_state_list=os.listdir(path6)\n",
    "#top_state_list # you  wil get state list\n",
    "\n",
    "\n",
    "#This is to extract the data's to create a dataframe\n",
    "\n",
    "cols6={'State':[], 'Year':[],'Quater':[],'Pincodes':[],\n",
    "       'RegisteredUsers':[]}\n",
    "\n",
    "for state in top_state_list:\n",
    "    cur_states=path6+state+\"/\"\n",
    "    top_yr=os.listdir(cur_states)\n",
    "    #top_yr # you will get year  list\n",
    "    \n",
    "    for year in top_yr:\n",
    "        cur_year=cur_states+year+\"/\"\n",
    "        top_file=os.listdir(cur_year)\n",
    "        #top_file  # you will get json files\n",
    "        \n",
    "        for file in top_file:\n",
    "            cur_file=cur_year+file\n",
    "            Data=open(cur_file,'r')\n",
    "            F=json.load(Data)\n",
    "            #print(F)   # you will get 1.json file details\n",
    "            \n",
    "            # slicing to get data\n",
    "            for i in F['data']['pincodes']:\n",
    "                entityName=i['name']\n",
    "                registeredUsers=i['registeredUsers']\n",
    "                cols6['Pincodes'].append(entityName)\n",
    "                cols6['RegisteredUsers'].append(registeredUsers)\n",
    "                cols6['State'].append(state)\n",
    "                cols6['Year'].append(year)\n",
    "                cols6['Quater'].append(int(file.strip('.json')))\n",
    "\n",
    "top_User=pd.DataFrame(cols6)   \n",
    "top_User['Year']= pd.to_datetime(top_User['Year']).dt.year \n",
    "top_User['State']= top_User['State'].str.replace(\"-\",\" \")\n",
    "top_User['State']= top_User['State'].str.title()\n",
    "top_User['State']= top_User['State'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "top_User['State']= top_User['State'].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagarhaveli and Daman  and Diu') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calling dataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agg_Trans\n",
    "# Agg_User\n",
    "# map_Trans\n",
    "# map_User\n",
    "# top_Trans\n",
    "# top_User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8924 entries, 0 to 8923\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   State              8924 non-null   object \n",
      " 1   Year               8924 non-null   int32  \n",
      " 2   Quater             8924 non-null   int64  \n",
      " 3   Pincodes           8922 non-null   object \n",
      " 4   Transacion_count   8924 non-null   int64  \n",
      " 5   Transacion_amount  8924 non-null   float64\n",
      "dtypes: float64(1), int32(1), int64(2), object(2)\n",
      "memory usage: 383.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pincodes\n",
       "744101    25\n",
       "122001    25\n",
       "737126    25\n",
       "737113    25\n",
       "737134    25\n",
       "          ..\n",
       "403801     1\n",
       "737139     1\n",
       "110094     1\n",
       "110042     1\n",
       "742202     1\n",
       "Name: count, Length: 780, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Agg_Trans['State'].unique())\n",
    "Agg_Trans['Quater'].unique()\n",
    "map_User.duplicated().sum()\n",
    "top_Trans['State'].values\n",
    "top_Trans.info()\n",
    "top_Trans.isna().sum()\n",
    "\n",
    "top_Trans['Pincodes'].value_counts()\n",
    "\n",
    "##top_Trans['Pincodes'].fillna(744101,inplace =True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as db\n",
    "db_connection =db.connect( host =\"localhost\",\n",
    "                          port = 3306,\n",
    "                          user = \"root\",\n",
    "                           password = \"root\",\n",
    "                           database =\"phonepe_project\")\n",
    "db_connection\n",
    "\n",
    "curr =db_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **  CREATING ENGINE TO SQL MIGRATION**\n",
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:root@localhost/phonepe_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\4082824426.py:1: UserWarning: The provided table name 'Agg_Trans' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  Agg_Trans.to_sql('Agg_Trans', con=engine, if_exists='replace', index=False)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\4082824426.py:2: UserWarning: The provided table name 'Agg_User' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  Agg_User.to_sql('Agg_User', con=engine, if_exists='replace', index=False)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\4082824426.py:3: UserWarning: The provided table name 'map_Trans' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  map_Trans.to_sql('map_Trans', con=engine, if_exists='replace', index=False)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\4082824426.py:4: UserWarning: The provided table name 'map_User' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  map_User.to_sql('map_User', con=engine,if_exists='replace', index=False)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\4082824426.py:5: UserWarning: The provided table name 'top_Trans' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  top_Trans.to_sql('top_Trans', con=engine ,if_exists='replace', index=False)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\4082824426.py:6: UserWarning: The provided table name 'top_User' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  top_User.to_sql('top_User', con=engine,if_exists='replace', index=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agg_Trans.to_sql('Agg_Trans', con=engine, if_exists='replace', index=False)\n",
    "Agg_User.to_sql('Agg_User', con=engine, if_exists='replace', index=False)\n",
    "map_Trans.to_sql('map_Trans', con=engine, if_exists='replace', index=False)\n",
    "map_User.to_sql('map_User', con=engine,if_exists='replace', index=False)\n",
    "top_Trans.to_sql('top_Trans', con=engine ,if_exists='replace', index=False)\n",
    "top_User.to_sql('top_User', con=engine,if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
